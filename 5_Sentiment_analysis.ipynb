{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## sentiment analysis \n",
    "## note that active directory is already set in thfunction_file_news_corpus\n",
    "## Keep all files in the same active dir\n",
    "## refer to line 48 and line 49 of the function file\n",
    "## $ conda install -c https://conda.anaconda.org/sloria textblob\n",
    "## refer to http://textblob.readthedocs.io/en/dev/install.html documentation \n",
    "\n",
    "\n",
    "from function_file_news_corpus import *\n",
    "from textblob import TextBlob\n",
    "def map_sentiment (text):\n",
    "    analyzer = TextBlob(text)\n",
    "    return analyzer.sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>year_quarter</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>sentiment_type</th>\n",
       "      <th>inf_topic</th>\n",
       "      <th>sub_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>0.043311</td>\n",
       "      <td>2018.1</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>rural_tribal_society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2018.1</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>general</td>\n",
       "      <td>rural_tribal_society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>0.149471</td>\n",
       "      <td>2018.1</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>rural_tribal_society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>0.147527</td>\n",
       "      <td>2018.1</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>rural_tribal_society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>0.134573</td>\n",
       "      <td>2017.4</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>general</td>\n",
       "      <td>rural_tribal_society</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic  sentiment  year_quarter  year  month  day  sentiment_type inf_topic  \\\n",
       "0     25   0.043311        2018.1  2018      3   24               1   general   \n",
       "1     25   0.000000        2018.1  2018      3    1               0   general   \n",
       "2     25   0.149471        2018.1  2018      1   12               1   general   \n",
       "3     25   0.147527        2018.1  2018      1   11               1   general   \n",
       "4     25   0.134573        2017.4  2017     12   30               1   general   \n",
       "\n",
       "              sub_topic  \n",
       "0  rural_tribal_society  \n",
       "1  rural_tribal_society  \n",
       "2  rural_tribal_society  \n",
       "3  rural_tribal_society  \n",
       "4  rural_tribal_society  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df_topics = pd.read_pickle('news_df_topics_for_sentiment_analysis_final.pkl')\n",
    "news_df_topics['sentiment'] = news_df_topics['text'].map(map_sentiment)\n",
    "\n",
    "## convert data time to an amenable format, year_quarter  \n",
    "\n",
    "def yr (text):\n",
    "    return int(str(text)[0:4])\n",
    "\n",
    "def mnth (text):\n",
    "    return int(str(text)[4:6])\n",
    "\n",
    "def qtr (text):\n",
    "    text =  int(str(text)[4:6])\n",
    "    if text <=3:\n",
    "        return 1\n",
    "    elif text <=6:\n",
    "        return 2\n",
    "    elif text <=9:\n",
    "        return 3\n",
    "    elif text <=9:\n",
    "        return 3\n",
    "    elif text <=12:\n",
    "        return 4\n",
    "    \n",
    "    \n",
    "def day (text):\n",
    "    return int(str(text)[-2:])\n",
    "\n",
    "\n",
    "news_df_topics['year'] = news_df_topics['date'].map(yr)\n",
    "news_df_topics['month'] = news_df_topics['date'].map(mnth)\n",
    "news_df_topics['quarter'] = news_df_topics['date'].map(qtr)\n",
    "news_df_topics['day'] = news_df_topics['date'].map(day)\n",
    "news_df_topics['year_quarter'] = news_df_topics['year'] + news_df_topics['quarter']/10\n",
    "\n",
    "\n",
    "news_df_sentiment_topic = news_df_topics[['topic','sentiment','year_quarter','year','month','day']].copy(deep=True)\n",
    "\n",
    "news_df_sentiment_topic['sentiment_type'] = np.where(news_df_sentiment_topic.sentiment>0, 1, -1)\n",
    "news_df_sentiment_topic['sentiment_type'] = np.where(news_df_sentiment_topic.sentiment == 0, \n",
    "                                                     0,news_df_sentiment_topic.sentiment_type )\n",
    "topic_key_final = pd.read_excel('topic_key_final.xlsx')\n",
    "news_df_sentiment_topic = pd.merge(news_df_sentiment_topic,topic_key_final,on=['topic'])\n",
    "news_df_sentiment_topic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('time_scatter_sentiment_topic.xlsx')\n",
    "news_df_sentiment_topic.to_excel(writer, sheet_name='time_scatter_sentiment')\n",
    "writer.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>year_quarter</th>\n",
       "      <th>mean_sentiment_topic_quarter</th>\n",
       "      <th>inf_topic</th>\n",
       "      <th>sub_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>0</td>\n",
       "      <td>2010.4</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>aadhaar_related_crime</td>\n",
       "      <td>fake_card | misuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>0</td>\n",
       "      <td>2011.1</td>\n",
       "      <td>-0.106250</td>\n",
       "      <td>aadhaar_related_crime</td>\n",
       "      <td>fake_card | misuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>0</td>\n",
       "      <td>2011.3</td>\n",
       "      <td>0.118750</td>\n",
       "      <td>aadhaar_related_crime</td>\n",
       "      <td>fake_card | misuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>0</td>\n",
       "      <td>2012.1</td>\n",
       "      <td>0.027473</td>\n",
       "      <td>aadhaar_related_crime</td>\n",
       "      <td>fake_card | misuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>0</td>\n",
       "      <td>2012.2</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>aadhaar_related_crime</td>\n",
       "      <td>fake_card | misuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>0</td>\n",
       "      <td>2012.3</td>\n",
       "      <td>-0.046429</td>\n",
       "      <td>aadhaar_related_crime</td>\n",
       "      <td>fake_card | misuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>0</td>\n",
       "      <td>2012.4</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>aadhaar_related_crime</td>\n",
       "      <td>fake_card | misuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>0</td>\n",
       "      <td>2013.3</td>\n",
       "      <td>-0.089167</td>\n",
       "      <td>aadhaar_related_crime</td>\n",
       "      <td>fake_card | misuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>0</td>\n",
       "      <td>2014.1</td>\n",
       "      <td>-0.110000</td>\n",
       "      <td>aadhaar_related_crime</td>\n",
       "      <td>fake_card | misuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>0</td>\n",
       "      <td>2014.2</td>\n",
       "      <td>-0.098830</td>\n",
       "      <td>aadhaar_related_crime</td>\n",
       "      <td>fake_card | misuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>0</td>\n",
       "      <td>2014.3</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>aadhaar_related_crime</td>\n",
       "      <td>fake_card | misuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>0</td>\n",
       "      <td>2014.4</td>\n",
       "      <td>-0.001056</td>\n",
       "      <td>aadhaar_related_crime</td>\n",
       "      <td>fake_card | misuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>0</td>\n",
       "      <td>2015.1</td>\n",
       "      <td>-0.002858</td>\n",
       "      <td>aadhaar_related_crime</td>\n",
       "      <td>fake_card | misuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2015.2</td>\n",
       "      <td>0.036152</td>\n",
       "      <td>aadhaar_related_crime</td>\n",
       "      <td>fake_card | misuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>0</td>\n",
       "      <td>2015.3</td>\n",
       "      <td>-0.027898</td>\n",
       "      <td>aadhaar_related_crime</td>\n",
       "      <td>fake_card | misuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>0</td>\n",
       "      <td>2015.4</td>\n",
       "      <td>0.062647</td>\n",
       "      <td>aadhaar_related_crime</td>\n",
       "      <td>fake_card | misuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>0</td>\n",
       "      <td>2016.1</td>\n",
       "      <td>0.024570</td>\n",
       "      <td>aadhaar_related_crime</td>\n",
       "      <td>fake_card | misuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0</td>\n",
       "      <td>2016.2</td>\n",
       "      <td>-0.097760</td>\n",
       "      <td>aadhaar_related_crime</td>\n",
       "      <td>fake_card | misuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>0</td>\n",
       "      <td>2016.3</td>\n",
       "      <td>-0.061054</td>\n",
       "      <td>aadhaar_related_crime</td>\n",
       "      <td>fake_card | misuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>0</td>\n",
       "      <td>2016.4</td>\n",
       "      <td>-0.029245</td>\n",
       "      <td>aadhaar_related_crime</td>\n",
       "      <td>fake_card | misuse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     topic  year_quarter  mean_sentiment_topic_quarter              inf_topic  \\\n",
       "919      0        2010.4                      0.244444  aadhaar_related_crime   \n",
       "918      0        2011.1                     -0.106250  aadhaar_related_crime   \n",
       "916      0        2011.3                      0.118750  aadhaar_related_crime   \n",
       "915      0        2012.1                      0.027473  aadhaar_related_crime   \n",
       "913      0        2012.2                      0.005000  aadhaar_related_crime   \n",
       "912      0        2012.3                     -0.046429  aadhaar_related_crime   \n",
       "911      0        2012.4                     -0.350000  aadhaar_related_crime   \n",
       "908      0        2013.3                     -0.089167  aadhaar_related_crime   \n",
       "907      0        2014.1                     -0.110000  aadhaar_related_crime   \n",
       "903      0        2014.2                     -0.098830  aadhaar_related_crime   \n",
       "902      0        2014.3                     -0.050000  aadhaar_related_crime   \n",
       "896      0        2014.4                     -0.001056  aadhaar_related_crime   \n",
       "892      0        2015.1                     -0.002858  aadhaar_related_crime   \n",
       "886      0        2015.2                      0.036152  aadhaar_related_crime   \n",
       "878      0        2015.3                     -0.027898  aadhaar_related_crime   \n",
       "872      0        2015.4                      0.062647  aadhaar_related_crime   \n",
       "868      0        2016.1                      0.024570  aadhaar_related_crime   \n",
       "863      0        2016.2                     -0.097760  aadhaar_related_crime   \n",
       "857      0        2016.3                     -0.061054  aadhaar_related_crime   \n",
       "842      0        2016.4                     -0.029245  aadhaar_related_crime   \n",
       "\n",
       "              sub_topic  \n",
       "919  fake_card | misuse  \n",
       "918  fake_card | misuse  \n",
       "916  fake_card | misuse  \n",
       "915  fake_card | misuse  \n",
       "913  fake_card | misuse  \n",
       "912  fake_card | misuse  \n",
       "911  fake_card | misuse  \n",
       "908  fake_card | misuse  \n",
       "907  fake_card | misuse  \n",
       "903  fake_card | misuse  \n",
       "902  fake_card | misuse  \n",
       "896  fake_card | misuse  \n",
       "892  fake_card | misuse  \n",
       "886  fake_card | misuse  \n",
       "878  fake_card | misuse  \n",
       "872  fake_card | misuse  \n",
       "868  fake_card | misuse  \n",
       "863  fake_card | misuse  \n",
       "857  fake_card | misuse  \n",
       "842  fake_card | misuse  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df_sentiment_topic['mean_sentiment_topic_quarter'] = news_df_sentiment_topic.groupby(['year_quarter', 'topic'])['sentiment'].transform('mean')\n",
    "\n",
    "plotly_mean_sentiment = news_df_sentiment_topic[['topic', 'year_quarter',\n",
    "                                                       'mean_sentiment_topic_quarter', 'inf_topic', 'sub_topic' ]].copy(deep=True)\n",
    "         \n",
    "plotly_mean_sentiment.drop_duplicates(inplace=True)\n",
    "\n",
    "plotly_mean_sentiment = plotly_mean_sentiment.sort_values(['topic', 'year_quarter'], ascending=[1, 1])\n",
    "plotly_mean_sentiment.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>year_quarter</th>\n",
       "      <th>mean_sentiment_topic_quarter</th>\n",
       "      <th>inf_topic</th>\n",
       "      <th>sub_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2010.4</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>aadhaar_related_crime</td>\n",
       "      <td>fake_card | misuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2011.1</td>\n",
       "      <td>-0.106250</td>\n",
       "      <td>aadhaar_related_crime</td>\n",
       "      <td>fake_card | misuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2011.3</td>\n",
       "      <td>0.118750</td>\n",
       "      <td>aadhaar_related_crime</td>\n",
       "      <td>fake_card | misuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2012.1</td>\n",
       "      <td>0.027473</td>\n",
       "      <td>aadhaar_related_crime</td>\n",
       "      <td>fake_card | misuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2012.2</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>aadhaar_related_crime</td>\n",
       "      <td>fake_card | misuse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic  year_quarter  mean_sentiment_topic_quarter              inf_topic  \\\n",
       "0      0        2010.4                      0.244444  aadhaar_related_crime   \n",
       "1      0        2011.1                     -0.106250  aadhaar_related_crime   \n",
       "2      0        2011.3                      0.118750  aadhaar_related_crime   \n",
       "3      0        2012.1                      0.027473  aadhaar_related_crime   \n",
       "4      0        2012.2                      0.005000  aadhaar_related_crime   \n",
       "\n",
       "            sub_topic  \n",
       "0  fake_card | misuse  \n",
       "1  fake_card | misuse  \n",
       "2  fake_card | misuse  \n",
       "3  fake_card | misuse  \n",
       "4  fake_card | misuse  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "merge_year_quarter = pd.read_excel('merge_year_quarter.xlsx')\n",
    "\n",
    "df_1 = list(plotly_mean_sentiment['topic'].unique())\n",
    "df_2 =list(merge_year_quarter['year_quarter'].unique())\n",
    "\n",
    "\n",
    "dfn = pd.DataFrame([(x, y) for x in df_1 for y in df_2])\n",
    "dfn.rename(columns={1:'year_quarter',0 :'topic' }, inplace=True)\n",
    "plotly_mean_sentiment= pd.merge(plotly_mean_sentiment,dfn,how='right',on=['year_quarter','topic'])\n",
    "\n",
    "#plotly_mean_sentiment.fillna(0, inplace = True)\n",
    "writer = pd.ExcelWriter('plotly_mean_sentiment.xlsx')\n",
    "plotly_mean_sentiment.to_excel(writer, sheet_name='plotly_mean_sentiment')\n",
    "writer.save()\n",
    "\n",
    "plotly_mean_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>year_quarter</th>\n",
       "      <th>mean_sentiment_topic_quarter</th>\n",
       "      <th>inf_topic</th>\n",
       "      <th>sub_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2010.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>aadhaar_related_crime</td>\n",
       "      <td>fake_card | misuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2011.1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>aadhaar_related_crime</td>\n",
       "      <td>fake_card | misuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2011.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>aadhaar_related_crime</td>\n",
       "      <td>fake_card | misuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2012.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>aadhaar_related_crime</td>\n",
       "      <td>fake_card | misuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2012.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>aadhaar_related_crime</td>\n",
       "      <td>fake_card | misuse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic  year_quarter  mean_sentiment_topic_quarter              inf_topic  \\\n",
       "0      0        2010.4                           1.0  aadhaar_related_crime   \n",
       "1      0        2011.1                          -1.0  aadhaar_related_crime   \n",
       "2      0        2011.3                           1.0  aadhaar_related_crime   \n",
       "3      0        2012.1                           1.0  aadhaar_related_crime   \n",
       "4      0        2012.2                           1.0  aadhaar_related_crime   \n",
       "\n",
       "            sub_topic  \n",
       "0  fake_card | misuse  \n",
       "1  fake_card | misuse  \n",
       "2  fake_card | misuse  \n",
       "3  fake_card | misuse  \n",
       "4  fake_card | misuse  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## analysis for values grouped by quarter:\n",
    "\n",
    "news_df_sentiment_topic['mean_sentiment_topic_quarter'] = news_df_sentiment_topic.groupby(['year_quarter', 'topic'])['sentiment_type'].transform('mean')\n",
    "\n",
    "plotly_mean_sentiment = news_df_sentiment_topic[['topic', 'year_quarter',\n",
    "                                                       'mean_sentiment_topic_quarter', 'inf_topic', 'sub_topic' ]].copy(deep=True)\n",
    "         \n",
    "plotly_mean_sentiment.drop_duplicates(inplace=True)\n",
    "\n",
    "plotly_mean_sentiment = plotly_mean_sentiment.sort_values(['topic', 'year_quarter'], ascending=[1, 1])\n",
    "plotly_mean_sentiment.head(n=20)\n",
    "\n",
    "\n",
    "merge_year_quarter = pd.read_excel('merge_year_quarter.xlsx')\n",
    "\n",
    "df_1 = list(plotly_mean_sentiment['topic'].unique())\n",
    "df_2 =list(merge_year_quarter['year_quarter'].unique())\n",
    "\n",
    "\n",
    "dfn = pd.DataFrame([(x, y) for x in df_1 for y in df_2])\n",
    "dfn.rename(columns={1:'year_quarter',0 :'topic' }, inplace=True)\n",
    "plotly_mean_sentiment= pd.merge(plotly_mean_sentiment,dfn,how='right',on=['year_quarter','topic'])\n",
    "\n",
    "active_dir = \"/Users/anirudhsyal/Desktop/Hindu_news/mean_positive_negative\"\n",
    "os.chdir (active_dir )\n",
    "\n",
    "\n",
    "#plotly_mean_sentiment.fillna(0, inplace = True)\n",
    "writer = pd.ExcelWriter('plotly_mean_sentiment.xlsx')\n",
    "plotly_mean_sentiment.to_excel(writer, sheet_name='plotly_mean_sentiment')\n",
    "writer.save()\n",
    "\n",
    "plotly_mean_sentiment.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Heading</th>\n",
       "      <th>original_text</th>\n",
       "      <th>doct_no</th>\n",
       "      <th>aadhaar_count</th>\n",
       "      <th>num_date</th>\n",
       "      <th>tokens</th>\n",
       "      <th>count_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>passion commitment research bedrock effort aim...</td>\n",
       "      <td>from aspiration to action</td>\n",
       "      <td>passion commitment and research are the bedro...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>20180324</td>\n",
       "      <td>[passion, commitment, research, bedrock, effor...</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sudden spurt abroad seek police clearance cert...</td>\n",
       "      <td>single window for police clearance certificates</td>\n",
       "      <td>after sudden spurt in people going abroad see...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20180320</td>\n",
       "      <td>[sudden, spurt, abroad, seek, police, clearanc...</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>municipal commissioner hari narayanan instruct...</td>\n",
       "      <td>firm action to ensure waste segregation</td>\n",
       "      <td>municipal commissioner m. hari narayanan has ...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>20180315</td>\n",
       "      <td>[municipal, commissioner, hari, narayanan, ins...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>despite recent reiteration unique_identificati...</td>\n",
       "      <td>despite clause services continue to be denied...</td>\n",
       "      <td>despite recent reiteration by the unique iden...</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>20180311</td>\n",
       "      <td>[despite, recent, reiteration, unique_identifi...</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>state convention democratic alliance knowledge...</td>\n",
       "      <td>flaws in digital india project</td>\n",
       "      <td>the state convention of democratic alliance f...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>20180311</td>\n",
       "      <td>[state, convention, democratic, alliance, know...</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  passion commitment research bedrock effort aim...   \n",
       "1  sudden spurt abroad seek police clearance cert...   \n",
       "2  municipal commissioner hari narayanan instruct...   \n",
       "3  despite recent reiteration unique_identificati...   \n",
       "4  state convention democratic alliance knowledge...   \n",
       "\n",
       "                                             Heading  \\\n",
       "0                         from aspiration to action    \n",
       "1   single window for police clearance certificates    \n",
       "2           firm action to ensure waste segregation    \n",
       "3   despite clause services continue to be denied...   \n",
       "4                    flaws in digital india project    \n",
       "\n",
       "                                       original_text  doct_no  aadhaar_count  \\\n",
       "0   passion commitment and research are the bedro...        1              3   \n",
       "1   after sudden spurt in people going abroad see...        2              1   \n",
       "2   municipal commissioner m. hari narayanan has ...        3              2   \n",
       "3   despite recent reiteration by the unique iden...        4             16   \n",
       "4   the state convention of democratic alliance f...        5              1   \n",
       "\n",
       "   num_date                                             tokens  count_tokens  \n",
       "0  20180324  [passion, commitment, research, bedrock, effor...           393  \n",
       "1  20180320  [sudden, spurt, abroad, seek, police, clearanc...           104  \n",
       "2  20180315  [municipal, commissioner, hari, narayanan, ins...            85  \n",
       "3  20180311  [despite, recent, reiteration, unique_identifi...           271  \n",
       "4  20180311  [state, convention, democratic, alliance, know...           172  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## analysis for all values \n",
    "\n",
    "news_df = pd.read_pickle('final_clean_hindu_corpus.pkl')\n",
    "news_df.drop(['DateTime'], axis = 1, inplace = True)\n",
    "\n",
    "news_df['tokens'] = news_df['text'].map(tokenizer_tf_idf)\n",
    "news_df['count_tokens'] = news_df['tokens'].map(len)\n",
    "news_df_count_all = news_df[['aadhaar_count','num_date','count_tokens']].copy(deep=True)\n",
    "\n",
    "writer = pd.ExcelWriter('news_df_count_all.xlsx')\n",
    "news_df_count_all.to_excel(writer, sheet_name='news_df_count_all')\n",
    "writer.save()\n",
    "\n",
    "news_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_quarter</th>\n",
       "      <th>num_date</th>\n",
       "      <th>count_tokens</th>\n",
       "      <th>aadhaar_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>2006.1</td>\n",
       "      <td>20060131</td>\n",
       "      <td>343</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>2006.1</td>\n",
       "      <td>20060204</td>\n",
       "      <td>349</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2613</th>\n",
       "      <td>2006.1</td>\n",
       "      <td>20060121</td>\n",
       "      <td>349</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2610</th>\n",
       "      <td>2006.2</td>\n",
       "      <td>20060415</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>2007.1</td>\n",
       "      <td>20070204</td>\n",
       "      <td>276</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year_quarter  num_date  count_tokens  aadhaar_count\n",
       "2612        2006.1  20060131           343              1\n",
       "2611        2006.1  20060204           349              1\n",
       "2613        2006.1  20060121           349              1\n",
       "2610        2006.2  20060415            29              1\n",
       "2608        2007.1  20070204           276              1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df['year'] = news_df['num_date'].map(yr)\n",
    "news_df['month'] = news_df['num_date'].map(mnth)\n",
    "news_df['quarter'] = news_df['num_date'].map(qtr)\n",
    "news_df['day'] = news_df['num_date'].map(day)\n",
    "news_df['year_quarter'] = news_df['year'] + news_df_topics['quarter']/10\n",
    "news_df_decriptive = news_df[['year_quarter','num_date','count_tokens','aadhaar_count' ]].copy(deep=True)\n",
    "news_df_decriptive.sort_values(['year_quarter','count_tokens', 'aadhaar_count'], ascending=[1, 1, 1], inplace = True)\n",
    "news_df_decriptive.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2614\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "news_df_decriptive['aadhaar_per_100_tokens'] = (100*news_df_decriptive['aadhaar_count' ]/ news_df_decriptive['count_tokens' ]).round(3)\n",
    "\n",
    "news_df_decriptive['mean_token_count'] = news_df_decriptive.groupby(['year_quarter'])['count_tokens'].transform('mean')\n",
    "\n",
    "news_df_decriptive['mean_aadhaar_count'] = news_df_decriptive.groupby(['year_quarter'])['aadhaar_count'].transform('mean')\n",
    "\n",
    "news_df_decriptive['mean_aadhaar_per_100_tokens'] = news_df_decriptive.groupby(['year_quarter'])['aadhaar_per_100_tokens'].transform('mean')\n",
    "\n",
    "news_df_decriptive['article_occurences'] = news_df_decriptive.groupby(['year_quarter'])['aadhaar_count'].transform('count')\n",
    "\n",
    "news_df_decriptive['aadhaar_occurences'] = news_df_decriptive.groupby(['year_quarter'])['aadhaar_count'].transform('sum')\n",
    "\n",
    "\n",
    "news_df_decriptive.drop(['num_date', 'count_tokens', 'aadhaar_count', 'aadhaar_per_100_tokens'], axis = 1, inplace = True)\n",
    "\n",
    "print(len(news_df_decriptive))\n",
    "news_df_decriptive.drop_duplicates(inplace=True)\n",
    "print(len(news_df_decriptive))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_quarter</th>\n",
       "      <th>mean_token_count</th>\n",
       "      <th>mean_aadhaar_count</th>\n",
       "      <th>mean_aadhaar_per_100_tokens</th>\n",
       "      <th>article_occurences</th>\n",
       "      <th>aadhaar_occurences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006.1</td>\n",
       "      <td>347.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.288667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006.2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.448000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2006.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2006.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007.1</td>\n",
       "      <td>304.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.331000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year_quarter  mean_token_count  mean_aadhaar_count  \\\n",
       "0         2006.1             347.0                 1.0   \n",
       "1         2006.2              29.0                 1.0   \n",
       "41        2006.3               0.0                 0.0   \n",
       "42        2006.4               0.0                 0.0   \n",
       "2         2007.1             304.5                 1.0   \n",
       "\n",
       "    mean_aadhaar_per_100_tokens  article_occurences  aadhaar_occurences  \n",
       "0                      0.288667                 3.0                 3.0  \n",
       "1                      3.448000                 1.0                 1.0  \n",
       "41                     0.000000                 0.0                 0.0  \n",
       "42                     0.000000                 0.0                 0.0  \n",
       "2                      0.331000                 2.0                 2.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "merge_year_quarter = pd.read_excel('merge_year_quarter.xlsx')\n",
    "\n",
    "#df_1 = list(plotly_mean_sentiment['topic'].unique())\n",
    "#df_2 =list(merge_year_quarter['year_quarter'].unique())\n",
    "\n",
    "\n",
    "#dfn = pd.DataFrame([(x, y) for x in df_1 for y in df_2])\n",
    "#dfn.rename(columns={1:'year_quarter',0 :'topic' }, inplace=True)\n",
    "news_df_decriptive= pd.merge(news_df_decriptive,merge_year_quarter,how='right',on=['year_quarter'])\n",
    "print(len(news_df_decriptive))\n",
    "news_df_decriptive.sort_values(['year_quarter'], ascending=[1], inplace = True)\n",
    "news_df_decriptive.fillna(0, inplace = True)\n",
    "news_df_decriptive.mean_aadhaar_per_100_tokens.round(3)\n",
    "news_df_decriptive.mean_token_count.round(1)\n",
    "news_df_decriptive.mean_aadhaar_count.round(1)\n",
    "news_df_decriptive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('news_df_decriptive_002.xlsx')\n",
    "news_df_decriptive.to_excel(writer, sheet_name='news_df_decriptive')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
